{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from numpy.testing.decorators import skipif\n",
    "import mvpa2.suite as mvpa\n",
    "from mvpa2.measures import rsa\n",
    "\n",
    "import utility_functions as uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All directories seem to be properly set up\n",
      "\n",
      "All file lists seem to be complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wider Output\n",
    "np.set_printoptions(edgeitems=20)\n",
    "\n",
    "# Project Directory\n",
    "project_dir = Path.cwd().parents[0]\n",
    "\n",
    "# Get Participant Files\n",
    "data_dir = project_dir.joinpath(\"data\", \"studyforrest-data-aligned\")\n",
    "ao_files = uf.get_files(data_dir, '*aomovie*nii.gz')\n",
    "av_files = uf.get_files(data_dir, '*avmovie*nii.gz')\n",
    "all_files = ao_files + av_files\n",
    "\n",
    "# Get Annotation Files\n",
    "anno_dir = project_dir.joinpath(\"data\", \"tmp\", \"speech_anno\")\n",
    "ao_anno_files = uf.get_files(anno_dir.joinpath(\"aomovie\"), '*.tsv')\n",
    "av_anno_files = uf.get_files(anno_dir.joinpath(\"avmovie\"), '*.tsv')\n",
    "\n",
    "# Get ROI Files\n",
    "mask_dir = project_dir.joinpath(\"data\", \"tmp\", \"masks_final_approach\", \"finished (inc. brain mask overlap)\")\n",
    "roi_masks_list = uf.get_files(mask_dir, '*.nii.gz')\n",
    "roi_masks_list = [mask for mask in roi_masks_list if \"all\" not in mask]\n",
    "\n",
    "# Reference Space + Warp Files\n",
    "template_dir = project_dir.joinpath(\"data\", \"studyforrest-data-templatetransforms\")\n",
    "ref = template_dir.joinpath(\"templates\", \"grpbold3Tp2\", \"brain.nii.gz\")\n",
    "warp_files = uf.get_files(template_dir, '*subj2tmpl_warp*.nii.gz')\n",
    "\n",
    "# Check if all components are good to go\n",
    "path_list = [project_dir, data_dir, anno_dir, template_dir, ref, mask_dir]\n",
    "file_lists = [ao_files, av_files, ao_anno_files, av_anno_files, warp_files, roi_masks_list]\n",
    "\n",
    "check = uf.check_all_components(path_list, file_lists)\n",
    "print \"{}\\n\".format(check[0])\n",
    "print \"{}\\n\".format(check[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Detected incorrect (nan) scl_ fields. Resetting to scl_slope=1.0 and scl_inter=0.0\n",
      " * Please note: warnings are printed only once, but underlying problem might occur many times *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkani/.local/lib/python2.7/site-packages/mvpa2/mappers/detrend.py:325: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  fit = np.linalg.lstsq(regs, ds.samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Boxcar mapper will use maximum boxlength (5) of all provided Events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arkani/.local/lib/python2.7/site-packages/mvpa2/mappers/boxcar.py:55: FutureWarning: Conversion of the second argument of issubdtype from `'i'` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype('i').type`.\n",
      "  if np.issubdtype(startpoints.dtype, 'i'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (377, 62115)\n",
      "\n",
      "Mask used: \n",
      "/home/arkani/Desktop/studyforrest_speaker_recognition/data/tmp/masks_final_approach/finished (inc. brain mask overlap)/all_ROIs.nii.gz\n",
      "\n",
      "Included unique events: ['FORREST' 'FORREST (V.O.)' 'LT. DAN' 'MRS. GUMP' 'Non-Speech']\n",
      "Number of included events: 377\n",
      "\n",
      "<DatasetAttributesCollection: imgaffine,imgtype,voxel_dim,voxel_eldim>\n",
      "<FeatureAttributesCollection: V1,aSTS,event_offsetidx,rIPL,rpSTS,speech,voxel_indices>\n",
      "<SampleAttributesCollection: chunks,duration,event_onsetidx,movie_type,onset,orig_duration,orig_offset,orig_onset,participant,targets,time_coords,time_indices>\n"
     ]
    }
   ],
   "source": [
    "# DS\n",
    "files_to_inc = sys.argv[1]\n",
    "\n",
    "if \"av\" in files_to_inc and \"ao\" in files_to_inc:\n",
    "    data_files = all_files[0:2]\n",
    "elif files_to_inc == \"av\":\n",
    "    data_files = av_files[0:2]\n",
    "elif files_to_inc == \"ao\":\n",
    "    data_files = ao_files[0:2]\n",
    "    \n",
    "key = \"preprocessed_df_{}.hdf5\".format(files_to_inc)\n",
    "\n",
    "# Output file name\n",
    "ds_save_p = project_dir.joinpath(\"data\", \"tmp\", key)\n",
    "\n",
    "# Mask to restrict the ds to all included ROIs\n",
    "mask = mask_dir.joinpath(\"all_ROIs.nii.gz\")\n",
    "\n",
    "# Targets to include\n",
    "targets = ['FORREST', 'MRS. GUMP', 'FORREST (V.O.)', 'LT. DAN']\n",
    "\n",
    "# Prep ROIs\n",
    "roi_info = uf.prepare_roi_info(roi_masks_list)\n",
    "\n",
    "# Preprocess each run for each participant individually\n",
    "ds = uf.load_create_save_ds(ds_save_p, data_files, ref, warp_files, mask, \n",
    "                            detrending=\"polynomial\", use_zscore=True, use_events=True, \n",
    "                            anno_dir=anno_dir, use_glm_estimates=False, targets=targets, \n",
    "                            event_offset=0, event_dur=8, rois=roi_info, save_disc_space=True)\n",
    "\n",
    "# print the used mask\n",
    "print \"Mask used: \\n{}\\n\".format(mask)\n",
    "\n",
    "# print the shape of the ds\n",
    "print \"Shape of the dataset: {}\\n\".format(ds.shape)\n",
    "\n",
    "# print roi info\n",
    "rois = [roi for roi in ds.fa if \"ROI\" in roi]\n",
    "for roi in rois:\n",
    "    sub_ds = ds[:, {roi: [1]}]\n",
    "    print \"Number of voxels included in the {}: {}\".format(roi, sub_ds.shape[1])\n",
    "print \"\\n\"\n",
    "\n",
    "# print event info \n",
    "all_events = ds.sa.targets\n",
    "unique_events = np.unique(all_events)\n",
    "num_events = len(ds.sa.targets)\n",
    "print \"Included targets: {}\".format(unique_events)\n",
    "print \"Number of included events: {}\\n\".format(num_events)\n",
    "\n",
    "print ds.a\n",
    "print ds.fa\n",
    "print ds.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
